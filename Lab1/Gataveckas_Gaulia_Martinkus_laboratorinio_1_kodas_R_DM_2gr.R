## ---- include=FALSE-----------------------------------------------------------------------------------------------
knitr::opts_chunk$set(warning = FALSE, message = FALSE)


## -----------------------------------------------------------------------------------------------------------------
library(tidyverse)

y <- read_csv("diabetes.csv")
y <- y %>% filter(BloodPressure != 0,BMI != 0)

table(y$Outcome)


## -----------------------------------------------------------------------------------------------------------------
# empirinės tikimybės

y_plot <- y %>% pivot_longer(1:8)


y_plot %>% ggplot(aes(value, Outcome)) +
  stat_summary(fun = mean, geom = "bar") +
  facet_wrap(vars(name), scales = "free") +
  scale_x_binned(n.breaks = 8) +
  theme_minimal()


## -----------------------------------------------------------------------------------------------------------------
# stačiakampės diagramos
y <- y %>% mutate(Outcome = factor(Outcome))
y_plot <- y_plot %>% mutate(Outcome = factor(Outcome))

y_plot %>% ggplot(aes(Outcome, value, fill = Outcome)) +
  geom_boxplot() +
  facet_wrap(vars(name), scales = "free") +
  theme_minimal()


## -----------------------------------------------------------------------------------------------------------------
library(caret)
library(yardstick)

model <- glm(
  formula = Outcome ~ ., family = binomial(logit),
  data = y
)

summary(model)

1-pchisq(model$null.deviance-model$deviance, model$df.null-model$df.residual) # globali nulinė hipotezė (tikėtinumo santykių testas likelihood ratio test)



1-pchisq(model$deviance,model$df.residual) # residual goodness-of-fit testas


# tikrinama, ar yra išskirtys
plot(cooks.distance(model))


confusionMatrix(factor(as.numeric(model$fitted.values > 0.5)), factor(y$Outcome),positive="1")


# plotas po ROC
y_2 <- y %>% mutate(pred = model$fitted.values)
roc_auc(y_2, Outcome, pred, event_level = "second")


## -----------------------------------------------------------------------------------------------------------------
# reikšminų kovariančių atranka
model_2 <- MASS::stepAIC(model,direction = "both")

anova(model, model_2, test = "Chisq") # modelis statistiškai reikšmingai nesiskiria nuo modelio su visomis kovariantėmis

model$aic
model_2$aic


confusionMatrix(factor(as.numeric(model_2$fitted.values > 0.5)), factor(y$Outcome),positive="1")


# koeficientų interpretacija
exp(coef(model_2))
exp(confint(model_2))


## -----------------------------------------------------------------------------------------------------------------
# modelio kovariačių efektai
library(effects)
plot(predictorEffects(model_2))


## -----------------------------------------------------------------------------------------------------------------
# ROC kreivė
library(cutpointr)

y_2 <- y %>% mutate(pred = model_2$fitted.values)

cp <- cutpointr(y_2, pred, Outcome,
  pos_class = "1", direction = ">=",
  method = maximize_metric, metric = youden
)


cp$roc_curve[[1]] %>%
  ggplot(aes(x = 1 - tnr, y = tpr)) +
  geom_path() +
  coord_equal() +
  geom_abline() +
  theme_bw() +
  xlab("1-Specificity") +
  ylab("Sensitivity")


roc_auc(y_2, Outcome, pred, event_level = "second")


## -----------------------------------------------------------------------------------------------------------------
# dėl didelio TN skaičiaus ROC rezultatai gali būti per daug optimistiški, todėl papildomai naudojama PR kreivė
cutoff <- cp$roc_curve[[1]] %>%
  filter(tpr >= 0.9) %>%
  pull(m) %>%
  max()

labels <- filter(cp$roc_curve[[1]], (m %in% c(max(m), cutoff))) %>% round(2)


cp$roc_curve[[1]] %>%
  ggplot(aes(x = tpr, y = tp / (fp + tp))) +
  geom_point(data = labels) +
  geom_text(data = labels, aes(label = x.sorted), nudge_y = 0.05) +
  geom_path() +
  coord_equal() +
  theme_bw() +
  xlab("Recall") +
  ylab("Precision")

# slenkstinių reikšmių parinkimas
# suskaičiuojamos optimalios slenkstinės reikšmės pagal Youden-J statistic ir pasirinkus ribą Sensitivity > 0.9
  # (t.y. siekiant aptikti bent 90% sergančiųjų)


## -----------------------------------------------------------------------------------------------------------------
# klasifikavimo lentelė su pasirinkta nauja slenkstine reikšme
confusionMatrix(factor(as.numeric(model_2$fitted.values >= 0.21)), factor(y$Outcome),positive="1")


## -----------------------------------------------------------------------------------------------------------------
# palyginimas su probit modeliu
model_3 <- glm(
  formula = Outcome ~ ., family = binomial(probit),
  data = y
)


model_3 <- MASS::stepAIC(model_3,direction = "both")

names(model_3$coefficients) == names(model_2$coefficients) 
# atrinktos tos pačios kovariantės


y_3 <- y %>% mutate(pred = model_3$fitted.values)


cp_2 <- cutpointr(y_3, pred, Outcome,
  method = maximize_metric, metric = F1_score
)


cp$roc_curve[[1]] %>%
  mutate(link = "logit") %>%
  rbind((cp_2$roc_curve[[1]] %>% mutate(link = "probit"))) %>%
  ggplot(aes(x = tpr, y = tp / (fp + tp), color = link)) +
  geom_path() +
  coord_equal() +
  theme_bw() +
  xlab("Recall") +
  ylab("Precision")
# skirtumų tarp modelių beveik nėra

